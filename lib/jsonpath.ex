defmodule JsonPath do
  @moduledoc """
  Minimal JSONPath implementation for Elixir.

  This module provides a simple JSONPath engine with:

    * Tokenization and parsing using LEEX and YECC generated Erlang modules.
    * AST evaluation against Elixir maps, lists, and primitives.
    * Full support for child, descendant, wildcard, slices, unions, and basic filters.
    * Convenience helper functions to query a map/list without manually parsing or tokenizing.

  ## Example

      iex> data = %{"store" => %{"book" => [%{"price" => 10}, %{"price" => 20}]}}
      iex> JsonPath.query(data, "$.store.book[*].price")
      [{"$['store']['book'][0]['price']", 10}, {"$['store']['book'][1]['price']", 20}]

  """

  @typedoc "JSONPath AST generated by the parser"
  @type ast :: {:jsonpath, :root, list(any())} | map() | {:path, list(any())}

  @typedoc "A node path in the JSON structure"
  @type path :: list(String.t() | integer())

  @typedoc "Result of evaluating a JSONPath AST: list of {path_string, value}"
  @type eval_result :: list({String.t(), any()})

  @typedoc "Result of tokenize/1"
  @type tokenize_result :: {:ok, list(any()), integer()} | {:error, any()}

  @typedoc "Result of parse/1"
  @type parse_result :: {:ok, ast()} | {:error, any()}

  @doc """
  Tokenizes a JSONPath query string into a list of tokens using the LEEX lexer.

  Returns `{:ok, tokens, line}` or `{:error, reason}`.

  ## Parameters

    * `query` - JSONPath string, e.g. "$.store.book[*].price"

  """
  @spec tokenize(String.t()) :: tokenize_result()
  def tokenize(query) when is_binary(query) do
    trimmed = String.trim(query)

    if trimmed != query do
      {:error, "JSONPath expressions cannot have leading or trailing whitespace"}
    else
      ensure_loaded(:jsonpath_lexer)
      :jsonpath_lexer.string(String.to_charlist(query))
    end
  end

  @doc """
  Parses a list of tokens into an AST using the YECC parser.

  Returns `{:ok, ast}` or `{:error, reason}`.
  """
  @spec parse(list(any())) :: parse_result()
  def parse(tokens) when is_list(tokens) do
    try do
      ensure_loaded(:jsonpath_parser)
      :jsonpath_parser.parse(tokens)
    rescue
      e in CaseClauseError -> {:error, e.term}
      e -> {:error, e.term}
    end
  end

  @doc """
  Evaluate a JSONPath AST against data.

  ## Parameters

  * `ast` - the parsed JSONPath AST
  * `data` - Elixir map or list to evaluate against

  ## Options
    * `:key_mode` - controls how keys are looked up in maps
      * `:string` (default) → only string keys (JSON spec)
      * `:atom` → only atom keys
      * `:both` → try string first, then atom

  ## Returns

  * list of tuples `{path_string, value}`
  """
  @spec evaluate(ast(), map() | list(), keyword()) :: eval_result() | {:error, any()}
  def evaluate(ast, data, opts \\ []) do
    opts_with_root = Keyword.put(opts, :root_data, data)

    case ast do
      {:jsonpath, :root, segments} when is_list(segments) ->
        traverse([{["$"], data}], segments, opts_with_root)

      %{root: :root, segments: segs} when is_list(segs) ->
        traverse([{["$"], data}], segs, opts_with_root)

      %{segments: segs} when is_list(segs) ->
        traverse([{["$"], data}], segs, opts_with_root)

      {:path, segs} when is_list(segs) ->
        traverse([{["$"], data}], segs, opts_with_root)

      other ->
        {:error, {:invalid_ast, other}}
    end
  end

  @doc """
  Convenience function: parse and evaluate a JSONPath query string in one call.


  ## Options
    * `:key_mode` - controls how keys are looked up in maps
      * `:string` (default) → only string keys (JSON spec)
      * `:atom` → only atom keys
      * `:both` → try string first, then atom

  ## Example

      iex> JsonPath.query(%{"a" => 1}, "$.a")
      [{"$['a']", 1}]
  """
  @spec query(map() | list(), String.t(), keyword()) :: eval_result() | {:error, any()}
  def query(data, path_string, opts \\ [])
      when is_binary(path_string) and (is_map(data) or is_list(data)) do
    with {:ok, tokens, _line} <- tokenize(path_string),
         {:ok, ast} <- parse(tokens) do
      evaluate(ast, data, opts)
    else
      {:error, reason} -> {:error, reason}
    end
  end

  ## PRIVATE HELPERS

  @spec ensure_loaded(module()) :: :ok
  defp ensure_loaded(module) do
    case :code.is_loaded(module) do
      {:file, _} -> :ok
      _ -> :code.load_file(module)
    end
  end

  @spec traverse(list({path(), any()}), list(any()), keyword()) :: eval_result()
  defp traverse(nodes, [], _opts),
    do: Enum.map(nodes, fn {p, v} -> {path_join(p), v} end)

  defp traverse(nodes, [seg | rest], opts) do
    # Pass root data through opts for absolute queries in filters
    root_data = Keyword.get(opts, :root_data)

    opts_with_root =
      if root_data, do: opts, else: Keyword.put(opts, :root_data, get_root_data(nodes))

    expanded =
      Enum.flat_map(nodes, fn {path, node} ->
        apply_segment(seg, {path, node}, opts_with_root)
      end)

    traverse(expanded, rest, opts_with_root)
  end

  # apply child or descendant segment
  defp apply_segment({child_type, selectors}, {path, node}, opts) do
    case child_type do
      :child ->
        Enum.flat_map(selectors, fn sel -> apply_selector(sel, {path, node}, opts) end)

      :descendant ->
        nodes = collect_descendants({path, node})

        Enum.flat_map(nodes, fn n ->
          Enum.flat_map(selectors, &apply_selector(&1, n, opts))
        end)
    end
  end

  defp collect_descendants({path, value}) do
    # include the node itself
    base = [{path, value}]

    children =
      case value do
        %{} = m ->
          Enum.flat_map(Map.to_list(m), fn {k, v} ->
            collect_descendants({path ++ [to_string(k)], v})
          end)

        l when is_list(l) ->
          Enum.with_index(l)
          |> Enum.flat_map(fn {v, idx} ->
            collect_descendants({path ++ [idx], v})
          end)

        _ ->
          []
      end

    base ++ children
  end

  defp apply_selector({:name, name}, {path, node}, opts) do
    case node do
      %{} = m ->
        case lookup(m, name, opts) do
          {:ok, v, actual_key} -> [{path ++ [actual_key], v}]
          :error -> []
        end

      _ ->
        []
    end
  end

  defp apply_selector({:wildcard}, {path, node}, _mode) do
    case node do
      %{} = m ->
        Enum.map(Map.to_list(m), fn {k, v} -> {path ++ [to_string(k)], v} end)

      l when is_list(l) ->
        Enum.with_index(l) |> Enum.map(fn {v, i} -> {path ++ [i], v} end)

      _ ->
        []
    end
  end

  defp apply_selector({:index, idx}, {path, node}, _mode) when is_integer(idx) do
    case node do
      l when is_list(l) ->
        n = length(l)
        real_i = if idx < 0, do: n + idx, else: idx
        if real_i >= 0 and real_i < n, do: [{path ++ [real_i], Enum.at(l, real_i)}], else: []

      _ ->
        []
    end
  end

  defp apply_selector({:slice, slice}, {path, node}, _mode) do
    case node do
      l when is_list(l) ->
        indices = normalize_slice(length(l), slice)
        Enum.map(indices, fn i -> {path ++ [i], Enum.at(l, i)} end)

      _ ->
        []
    end
  end

  defp apply_selector({:union, items}, {path, node}, mode) do
    Enum.flat_map(items, fn item ->
      apply_selector(item, {path, node}, mode)
    end)
  end

  defp apply_selector({:filter, expr}, {path, node}, opts) do
    case node do
      l when is_list(l) ->
        Enum.with_index(l)
        |> Enum.flat_map(fn {v, i} ->
          if eval_filter(expr, v, opts), do: [{path ++ [i], v}], else: []
        end)

      %{} = m ->
        Enum.flat_map(Map.to_list(m), fn {k, v} ->
          if eval_filter(expr, v, opts), do: [{path ++ [to_string(k)], v}], else: []
        end)

      _ ->
        []
    end
  end

  # slice normalization: accepts slice shape produced by parser
  defp normalize_slice(len, {:start_end_step, s, e, step}) do
    range_from_slice(len, s, e, step)
  end

  defp normalize_slice(len, {:start_end, s, e}), do: range_from_slice(len, s, e, 1)
  defp normalize_slice(len, {:start_omitted_end, e}), do: range_from_slice(len, 0, e, 1)
  defp normalize_slice(len, {:start_end_omitted, s}), do: range_from_slice(len, s, len, 1)

  defp normalize_slice(len, {:start_omitted_end_step, step}),
    do: range_from_slice(len, 0, len, step)

  defp normalize_slice(_len, {:omitted_all}), do: []

  defp range_from_slice(len, start, stop, step) do
    st = if start < 0, do: max(len + start, 0), else: min(start, len)
    sp = if stop < 0, do: max(len + stop, 0), else: min(stop, len)

    cond do
      step == 0 ->
        []

      step > 0 ->
        if st >= sp do
          []
        else
          st..(sp - 1)//step |> Enum.to_list()
        end

      step < 0 ->
        if st <= sp do
          []
        else
          st..(sp + 1)//step |> Enum.to_list()
        end
    end
  end

  ## FILTER EVAL: evaluation of filter AST nodes against a value.
  ## Basic implementation: literals, existence tests via `@.name` are supported, comparisons.

  defp eval_filter({:or, a, b}, node, opts),
    do: eval_filter(a, node, opts) or eval_filter(b, node, opts)

  defp eval_filter({:and, a, b}, node, opts),
    do: eval_filter(a, node, opts) and eval_filter(b, node, opts)

  defp eval_filter({:not, a}, node, opts), do: not eval_filter(a, node, opts)

  defp eval_filter({:cmp, op, left, right}, node, opts) do
    l = eval_primary(left, node, opts)
    r = eval_primary(right, node, opts)
    compare_values(op, l, r)
  end

  defp eval_filter({:query, :relative, qsegs}, node, _opts) do
    results = run_singular_query(node, qsegs)
    length(results) > 0
  end

  defp eval_filter({:query, :absolute, qsegs}, _node, opts) do
    case Keyword.get(opts, :root_data) do
      nil ->
        # No root data available, cannot evaluate absolute query
        false

      root_data ->
        # Execute absolute query from root
        results = run_singular_query(root_data, qsegs)
        length(results) > 0
    end
  end

  defp eval_filter({:function, name, args}, node, opts) do
    evaluated_args = Enum.map(args, &eval_primary(&1, node, opts))
    apply_function(name, evaluated_args, node)
  end

  defp eval_primary({:function, name, args}, node, opts) do
    evaluated_args = Enum.map(args, &eval_primary(&1, node, opts))
    apply_function(name, evaluated_args, node)
  end

  defp eval_primary({:lit, v}, _node, _opts), do: v

  defp eval_primary({:query, :relative, qsegs}, node, _opts) do
    case run_singular_query(node, qsegs) do
      [{_path, val} | _] -> val
      [] -> nil
    end
  end

  defp eval_primary({:query, :absolute, qsegs}, _node, opts) do
    case Keyword.get(opts, :root_data) do
      nil ->
        nil

      root_data ->
        case run_singular_query(root_data, qsegs) do
          [{_path, val} | _] -> val
          [] -> nil
        end
    end
  end

  defp apply_function("length", [value], _node) when is_list(value), do: length(value)
  defp apply_function("length", [value], _node) when is_map(value), do: map_size(value)
  defp apply_function("length", [_], _node), do: 0

  defp apply_function("value", [query_result], _node) do
    # value() function extracts the first result from a query
    case query_result do
      [{_path, val} | _] -> val
      [] -> nil
      # if already a literal
      val -> val
    end
  end

  defp apply_function("count", args, _node), do: length(args)
  # Unknown function
  defp apply_function(_name, _args, _node), do: nil

  defp compare_values(:eq, a, b), do: a == b
  defp compare_values(:ne, a, b), do: a != b
  defp compare_values(:lt, a, b) when is_number(a) and is_number(b), do: a < b
  defp compare_values(:le, a, b) when is_number(a) and is_number(b), do: a <= b
  defp compare_values(:gt, a, b) when is_number(a) and is_number(b), do: a > b
  defp compare_values(:ge, a, b) when is_number(a) and is_number(b), do: a >= b
  defp compare_values(_, _, _), do: false

  defp run_singular_query(node, qsegs) do
    # qsegs is list of {:qname, name} or {:qindex, idx}
    # start at node with path []
    walk_query([{[], node}], qsegs)
  end

  defp walk_query(nodes, []), do: nodes

  defp walk_query(nodes, [seg | rest]) do
    next =
      Enum.flat_map(nodes, fn {path, node} ->
        case seg do
          {:qname, name} ->
            case node do
              %{} = m ->
                name_str = to_string(name)

                case Map.fetch(m, name_str) do
                  {:ok, v} -> [{path ++ [name_str], v}]
                  :error -> []
                end

              _ ->
                []
            end

          {:qindex, idx} when is_integer(idx) ->
            case node do
              l when is_list(l) ->
                n = length(l)
                i = if idx < 0, do: n + idx, else: idx
                if i >= 0 and i < n, do: [{path ++ [i], Enum.at(l, i)}], else: []

              _ ->
                []
            end

          {:qwildcard} ->
            case node do
              %{} = m ->
                Enum.map(Map.to_list(m), fn {k, v} -> {path ++ [to_string(k)], v} end)

              l when is_list(l) ->
                Enum.with_index(l) |> Enum.map(fn {v, i} -> {path ++ [i], v} end)

              _ ->
                []
            end

          {:qslice, slice} ->
            case node do
              l when is_list(l) ->
                indices = normalize_slice(length(l), slice)
                Enum.map(indices, fn i -> {path ++ [i], Enum.at(l, i)} end)

              _ ->
                []
            end
        end
      end)

    walk_query(next, rest)
  end

  defp path_join(parts) do
    "$" <>
      Enum.map_join(tl(parts), "", fn
        part when is_integer(part) -> "[#{part}]"
        part when is_binary(part) -> "['#{part}']"
        part when is_atom(part) -> "['#{Atom.to_string(part)}']"
      end)
  end

  defp lookup(map, key, opts) when is_map(map) do
    mode = Keyword.get(opts, :key_mode, :string)

    case {mode, key} do
      {:string, k} ->
        case Map.fetch(map, to_string(k)) do
          {:ok, v} -> {:ok, v, to_string(k)}
          :error -> :error
        end

      {:atom, k} when is_binary(k) ->
        atom_key = String.to_existing_atom(k)

        case Map.fetch(map, atom_key) do
          {:ok, v} -> {:ok, v, atom_key}
          :error -> :error
        end

      {:both, k} ->
        str_k = to_string(k)

        case Map.fetch(map, str_k) do
          {:ok, v} ->
            {:ok, v, str_k}

          :error ->
            atom_k = String.to_existing_atom(str_k)

            case Map.fetch(map, atom_k) do
              {:ok, v} -> {:ok, v, atom_k}
              :error -> :error
            end
        end
    end
  end

  defp get_root_data([{["$"], root_data} | _]), do: root_data
  defp get_root_data(_), do: nil
end
