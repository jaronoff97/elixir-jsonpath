defmodule JsonPath do
  @moduledoc """
  Minimal JSONPath implementation for Elixir.

  This module provides a simple JSONPath engine with:

    * Tokenization and parsing using LEEX and YECC generated Erlang modules.
    * AST evaluation against Elixir maps, lists, and primitives.
    * Full support for child, descendant, wildcard, slices, unions, and basic filters.
    * Convenience helper functions to query a map/list without manually parsing or tokenizing.

  ## Example

      iex> data = %{"store" => %{"book" => [%{"price" => 10}, %{"price" => 20}]}}
      iex> JsonPath.query(data, "$.store.book[*].price")
      [{"$['store']['book'][0]['price']", 10}, {"$['store']['book'][1]['price']", 20}]

  """

  @typedoc "JSONPath AST generated by the parser"
  @type ast :: {:jsonpath, :root, list(any())} | map() | {:path, list(any())}

  @typedoc "A node path in the JSON structure"
  @type path :: list(String.t() | integer())

  @typedoc "Result of evaluating a JSONPath AST: list of {path_string, value}"
  @type eval_result :: list({String.t(), any()})

  @typedoc "Result of tokenize/1"
  @type tokenize_result :: {:ok, list(any()), integer()} | {:error, any()}

  @typedoc "Result of parse/1"
  @type parse_result :: {:ok, ast()} | {:error, any()}

  @doc """
  Tokenizes a JSONPath query string into a list of tokens using the LEEX lexer.

  Returns `{:ok, tokens, line}` or `{:error, reason}`.

  ## Parameters

    * `query` - JSONPath string, e.g. "$.store.book[*].price"

  """
  @spec tokenize(String.t()) :: tokenize_result()
  def tokenize(query) when is_binary(query) do
    trimmed = String.trim(query)

    if trimmed != query do
      {:error, "JSONPath expressions cannot have leading or trailing whitespace"}
    else
      ensure_loaded(:jsonpath_lexer)
      :jsonpath_lexer.string(String.to_charlist(query))
    end
  end

  @doc """
  Parses a list of tokens into an AST using the YECC parser.

  Returns `{:ok, ast}` or `{:error, reason}`.
  """
  @spec parse(list(any())) :: parse_result()
  def parse(tokens) when is_list(tokens) do
    try do
      ensure_loaded(:jsonpath_parser)
      :jsonpath_parser.parse(tokens)
    rescue
      e in CaseClauseError -> {:error, e.term}
      e -> {:error, e.term}
    end
  end

  @doc """
  Evaluate a JSONPath AST against data.

  ## Parameters

  * `ast` - the parsed JSONPath AST
  * `data` - Elixir map or list to evaluate against

  ## Options
    * `:key_mode` - controls how keys are looked up in maps
      * `:string` (default) → only string keys (JSON spec)
      * `:atom` → only atom keys
      * `:both` → try string first, then atom

  ## Returns

  * list of tuples `{path_string, value}`
  """
  @spec evaluate(ast(), map() | list(), keyword()) :: eval_result() | {:error, any()}
  def evaluate(ast, data, opts \\ []) do
    opts_with_root = Keyword.put(opts, :root_data, data)

    case ast do
      {:jsonpath, :root, segments} when is_list(segments) ->
        traverse([{["$"], data}], segments, opts_with_root)

      %{root: :root, segments: segs} when is_list(segs) ->
        traverse([{["$"], data}], segs, opts_with_root)

      %{segments: segs} when is_list(segs) ->
        traverse([{["$"], data}], segs, opts_with_root)

      {:path, segs} when is_list(segs) ->
        traverse([{["$"], data}], segs, opts_with_root)

      other ->
        {:error, {:invalid_ast, other}}
    end
  end

  @doc """
  Convenience function: parse and evaluate a JSONPath query string in one call.


  ## Options
    * `:key_mode` - controls how keys are looked up in maps
      * `:string` (default) → only string keys (JSON spec)
      * `:atom` → only atom keys
      * `:both` → try string first, then atom

  ## Example

      iex> JsonPath.query(%{"a" => 1}, "$.a")
      [{"$['a']", 1}]
  """
  @spec query(map() | list(), String.t(), keyword()) :: eval_result() | {:error, any()}
  def query(data, path_string, opts \\ [])
      when is_binary(path_string) and (is_map(data) or is_list(data)) do
    with {:ok, tokens, _line} <- tokenize(path_string),
         {:ok, ast} <- parse(tokens) do
      evaluate(ast, data, opts)
    else
      {:error, reason} -> {:error, reason}
    end
  end

  ## PRIVATE HELPERS

  @spec ensure_loaded(module()) :: :ok
  defp ensure_loaded(module) do
    case :code.is_loaded(module) do
      {:file, _} -> :ok
      _ -> :code.load_file(module)
    end
  end

  @spec traverse(list({path(), any()}), list(any()), keyword()) :: eval_result()
  defp traverse(nodes, [], _opts),
    do: Enum.map(nodes, fn {p, v} -> {path_join(p), v} end)

  defp traverse(nodes, [seg | rest], opts) do
    # Pass root data through opts for absolute queries in filters
    root_data = Keyword.get(opts, :root_data)

    opts_with_root =
      if root_data, do: opts, else: Keyword.put(opts, :root_data, get_root_data(nodes))

    IO.inspect(nodes, label: :nodes)

    expanded =
      Enum.flat_map(nodes, fn {path, node} ->
        apply_segment(seg, {path, node}, opts_with_root)
      end)

    IO.inspect(expanded, label: :expanded)
    traverse(expanded, rest, opts_with_root)
  end

  # apply child or descendant segment
  defp apply_segment({child_type, selectors}, {path, node}, opts) do
    IO.inspect({child_type, selectors, path, node}, label: "apply_segment")

    case child_type do
      :child ->
        result =
          Enum.flat_map(selectors, fn sel ->
            IO.inspect({:applying_child_selector, sel}, label: "child_selector")
            apply_selector(sel, {path, node}, opts)
          end)

        IO.inspect(result, label: "child_result")
        result

      :descendant ->
        nodes = collect_descendants({path, node})
        IO.inspect(nodes, label: :descendant_nodes)

        result =
          Enum.flat_map(nodes, fn n ->
            IO.inspect({:applying_descendant_selector_to, n}, label: "descendant_node")

            Enum.flat_map(selectors, fn sel ->
              IO.inspect({:selector, sel}, label: "descendant_selector")
              apply_selector(sel, n, opts)
            end)
          end)

        IO.inspect(result, label: "descendant_result")
        result
    end
  end

  defp collect_descendants({path, value}) do
    # include the node itself
    base = [{path, value}]
    IO.inspect({path, value, "collecting_descendants"}, label: "collect_start")

    children =
      case value do
        %{} = m ->
          IO.inspect({path, m, "map_descendants"}, label: "collect_map")

          result =
            Enum.flat_map(Map.to_list(m), fn {k, v} ->
              child_path = path ++ [to_string(k)]
              IO.inspect({child_path, v, "recursing_into_map_child"}, label: "collect_map_child")
              collect_descendants({child_path, v})
            end)

          IO.inspect(result, label: "map_children_result")
          result

        l when is_list(l) ->
          IO.inspect({path, l, "list_descendants"}, label: "collect_list")

          result =
            Enum.with_index(l)
            |> Enum.flat_map(fn {v, idx} ->
              child_path = path ++ [idx]

              IO.inspect({child_path, v, "recursing_into_list_child"},
                label: "collect_list_child"
              )

              collect_descendants({child_path, v})
            end)

          IO.inspect(result, label: "list_children_result")
          result

        _ ->
          IO.inspect({path, value, "primitive_no_descendants"}, label: "collect_primitive")
          []
      end

    total_result = base ++ children
    IO.inspect(total_result, label: "collect_total_result for #{inspect(path)}")
    total_result
  end

  defp apply_selector({:name, name}, {path, node}, opts) do
    case node do
      %{} = m ->
        case lookup(m, name, opts) do
          {:ok, v, actual_key} -> [{path ++ [actual_key], v}]
          :error -> []
        end

      _ ->
        []
    end
  end

  defp apply_selector({:wildcard}, {path, node}, _mode) do
    case node do
      %{} = m ->
        Enum.map(Map.to_list(m), fn {k, v} -> {path ++ [to_string(k)], v} end)

      l when is_list(l) ->
        Enum.with_index(l) |> Enum.map(fn {v, i} -> {path ++ [i], v} end)

      _ ->
        []
    end
  end

  defp apply_selector({:index, idx}, {path, node}, _mode) when is_integer(idx) do
    case node do
      l when is_list(l) ->
        n = length(l)
        real_i = if idx < 0, do: n + idx, else: idx
        if real_i >= 0 and real_i < n, do: [{path ++ [real_i], Enum.at(l, real_i)}], else: []

      _ ->
        []
    end
  end

  defp apply_selector({:slice, slice}, {path, node}, _mode) do
    case node do
      l when is_list(l) ->
        indices = normalize_slice(length(l), slice)
        Enum.map(indices, fn i -> {path ++ [i], Enum.at(l, i)} end)

      _ ->
        []
    end
  end

  defp apply_selector({:union, items}, {path, node}, mode) do
    Enum.flat_map(items, fn item ->
      apply_selector(item, {path, node}, mode)
    end)
  end

  defp apply_selector({:filter, expr}, {path, node}, opts) do
    IO.inspect({:applying_filter, expr, path, node}, label: "filter_application")

    case node do
      l when is_list(l) ->
        IO.inspect(l, label: :filtering_list)

        Enum.with_index(l)
        |> Enum.flat_map(fn {v, i} ->
          filter_result = eval_filter(expr, v, opts)
          IO.inspect({v, expr, filter_result}, label: "list_filter_eval")
          if filter_result, do: [{path ++ [i], v}], else: []
        end)

      %{} = m ->
        IO.inspect(m, label: :filtering_map_directly)
        # This branch handles when we're filtering a map directly (not its contents)
        # We need to apply the filter to the map itself
        filter_result = eval_filter(expr, m, opts)
        IO.inspect({m, expr, filter_result}, label: "direct_map_filter_eval")
        if filter_result, do: [{path, m}], else: []

      s when is_binary(s) ->
        filter_result = eval_filter(expr, s, opts)
        IO.inspect({s, expr, filter_result}, label: "string_filter_eval")
        if filter_result, do: [{path, s}], else: []

      _ ->
        IO.inspect({node, "no_filter_applicable"}, label: "filter_skip")
        []
    end
  end

  # slice normalization: accepts slice shape produced by parser
  defp normalize_slice(len, {:start_end_step, s, e, step}) do
    range_from_slice(len, s, e, step)
  end

  defp normalize_slice(len, {:start_end, s, e}), do: range_from_slice(len, s, e, 1)

  defp normalize_slice(len, {:start_end_omitted_step, s, step}),
    do: range_from_slice(len, s, nil, step)

  defp normalize_slice(len, {:start_omitted_end, e}), do: range_from_slice(len, nil, e, 1)

  defp normalize_slice(len, {:start_omitted_end_step, e, step}),
    do: range_from_slice(len, nil, e, step)

  defp normalize_slice(len, {:start_end_omitted, s}), do: range_from_slice(len, s, nil, 1)

  defp normalize_slice(len, {:start_omitted_end_step, step}),
    do: range_from_slice(len, nil, nil, step)

  defp normalize_slice(len, {:omitted_all}), do: range_from_slice(len, nil, nil, 1)

  defp range_from_slice(len, start, stop, step) do
    step = step || 1

    # Return empty for zero step
    if step == 0 do
      []
    else
      # Handle negative indices and nil values
      {st, sp} = normalize_start_stop(len, start, stop, step)

      # Generate the range
      generate_range(st, sp, step)
    end
  end

  defp normalize_start_stop(len, start, stop, step) do
    # Normalize start
    st =
      case start do
        nil when step > 0 -> 0
        nil when step < 0 -> len - 1
        # Handle negative indices
        n when n < 0 -> max(0, len + n)
        # Out of bounds positive start
        n when n >= len and step > 0 -> len
        # Out of bounds positive start with negative step
        n when n >= len and step < 0 -> len - 1
        # Normal positive index, but ensure >= 0
        n -> max(0, n)
      end

    # Normalize stop
    sp =
      case stop do
        nil when step > 0 -> len
        nil when step < 0 -> -1
        # Handle negative indices, allow -1 for negative step
        n when n < 0 -> max(-1, len + n)
        # For positive step, cap at len
        n when step > 0 -> min(n, len)
        # For negative step, don't cap positive stop values
        n -> n
      end

    # Additional bounds checking for start
    st =
      cond do
        # Start beyond array for positive step
        step > 0 and st >= len -> len
        # Start before array for negative step
        step < 0 and st < 0 -> -1
        # Ensure non-negative for positive step
        step > 0 -> max(0, st)
        # Cap at last valid index for negative step
        step < 0 -> min(st, len - 1)
        true -> st
      end

    {st, sp}
  end

  defp generate_range(st, sp, step) when step > 0 do
    if st >= sp do
      []
    else
      # For positive step: start..(stop-1)//step
      Enum.to_list(st..(sp - 1)//step)
    end
  end

  defp generate_range(st, sp, step) when step < 0 do
    if st <= sp do
      []
    else
      # For negative step: start..(stop+1)//step
      Enum.to_list(st..(sp + 1)//step)
    end
  end

  ## FILTER EVAL: evaluation of filter AST nodes against a value.
  ## Basic implementation: literals, existence tests via `@.name` are supported, comparisons.

  defp eval_filter({:or, a, b}, node, opts),
    do: eval_filter(a, node, opts) or eval_filter(b, node, opts)

  defp eval_filter({:and, a, b}, node, opts),
    do: eval_filter(a, node, opts) and eval_filter(b, node, opts)

  defp eval_filter({:not, a}, node, opts), do: not eval_filter(a, node, opts)

  defp eval_filter({:cmp, op, left, right}, node, opts) do
    l = eval_primary(left, node, opts)
    r = eval_primary(right, node, opts)
    IO.inspect({l, r, compare_values(op, l, r)}, label: "cmp l r")
    compare_values(op, l, r)
  end

  defp eval_filter({:query, :relative, qsegs}, node, _opts) do
    results = run_singular_query(node, qsegs)
    IO.inspect(results, label: "filter_query_results for #{inspect(node)}")

    # Check if we got any non-nil results
    case results do
      [] -> false
      # Explicitly handle nil values
      [{_path, nil}] -> false
      [{_path, _value} | _] -> true
      _ -> false
    end
  end

  defp eval_filter({:query, :absolute, qsegs}, _node, opts) do
    case Keyword.get(opts, :root_data) do
      nil ->
        false

      root_data ->
        results = run_singular_query(root_data, qsegs)
        IO.inspect(results, label: "absolute_filter_query_results")

        # Check if we got any non-nil results
        case results do
          [] -> false
          # Explicitly handle nil values
          [{_path, nil}] -> false
          [{_path, _value} | _] -> true
          _ -> false
        end
    end
  end

  defp eval_filter({:function, name, args}, node, opts) do
    evaluated_args = Enum.map(args, &eval_primary(&1, node, opts))
    IO.inspect({name, evaluated_args, node}, label: :eval_filter_function)
    apply_function(name, evaluated_args, node)
  end

  defp eval_primary({:function, name, args}, node, opts) do
    evaluated_args = Enum.map(args, &eval_primary(&1, node, opts))

    IO.inspect({name, evaluated_args, node, apply_function(name, evaluated_args, node)},
      label: :eval_primary_function
    )

    apply_function(name, evaluated_args, node)
  end

  defp eval_primary({:lit, :null}, _node, _opts), do: nil
  defp eval_primary({:lit, v}, _node, _opts), do: v

  defp eval_primary({:query, :relative, qsegs}, node, _opts) do
    case run_singular_query(node, qsegs) do
      [] -> :nothing
      [{_path, val} | _] -> val
    end
  end

  defp eval_primary({:query, :absolute, qsegs}, _node, opts) do
    case Keyword.get(opts, :root_data) do
      nil ->
        nil

      root_data ->
        case run_singular_query(root_data, qsegs) do
          [{_path, val} | _] -> val
          [] -> nil
        end
    end
  end

  defp apply_function("length", [value], _node) do
    cond do
      is_list(value) ->
        length(value)

      is_map(value) ->
        map_size(value)

      is_binary(value) ->
        String.length(value)

      match?([_ | _], value) and is_tuple(hd(value)) ->
        # JSONPath query result list of {path, val}
        length(value)

      true ->
        0
    end
  end

  defp apply_function("value", [query_result], _node) do
    # value() function extracts the first result from a query
    case query_result do
      [{_path, val} | _] -> val
      [] -> nil
      # if already a literal
      val -> val
    end
  end

  defp apply_function("count", [query_result], _node) do
    # count() function counts the number of nodes returned by a query
    case query_result do
      # Query result is a list of {path, value} tuples
      results when is_list(results) ->
        length(results)

      # If it's a single value, count as 1
      _ ->
        1
    end
  end

  defp apply_function("match", [str, re], _nodes) when is_binary(str) and is_binary(re),
    do: Regex.match?(Regex.compile!("^#{re}$"), str)

  defp apply_function("search", [str, re], _nodes) when is_binary(str) and is_binary(re) do
    regex = Regex.compile!(re)

    case Regex.run(regex, str) do
      # no substring match
      nil -> false
      # at least one substring match
      _ -> true
    end
  end

  # Unknown function
  defp apply_function(_name, _args, _node), do: nil
  # Entry point
  defp compare_values(:eq, a, b), do: equal?(a, b)
  defp compare_values(:lt, a, b), do: less?(a, b)

  defp compare_values(:ne, a, b), do: not compare_values(:eq, a, b)
  defp compare_values(:le, a, b), do: compare_values(:lt, a, b) or compare_values(:eq, a, b)
  defp compare_values(:gt, a, b), do: compare_values(:lt, b, a)
  defp compare_values(:ge, a, b), do: compare_values(:gt, a, b) or compare_values(:eq, a, b)

  defp compare_values(_, _, _), do: false

  # --- RFC helpers ---

  # equality
  defp equal?(a, b) do
    cond do
      a == nil and b == nil ->
        true

      # empty nodelist / Nothing handling
      a == :nothing and b == :nothing ->
        true

      a == :nothing and b == [] ->
        true

      b == :nothing and a == [] ->
        true

      a == :nothing or b == :nothing ->
        false

      a == [] and b == [] ->
        true

      a == [] or b == [] ->
        false

      # numbers (I-JSON interop assumed, i.e. IEEE 754 doubles + int64)
      is_number(a) and is_number(b) ->
        a == b

      # strings
      is_binary(a) and is_binary(b) ->
        a == b

      # booleans
      is_boolean(a) and is_boolean(b) ->
        a == b

      # arrays
      is_list(a) and is_list(b) ->
        length(a) == length(b) and Enum.zip(a, b) |> Enum.all?(fn {x, y} -> equal?(x, y) end)

      # objects (no duplicate keys)
      is_map(a) and is_map(b) ->
        Map.keys(a) |> Enum.sort() == Map.keys(b) |> Enum.sort() and
          Enum.all?(Map.keys(a), fn k -> equal?(Map.fetch!(a, k), Map.fetch!(b, k)) end)

      true ->
        false
    end
  end

  # ordering (<)
  defp less?(a, b) do
    cond do
      # empty nodelists / Nothing => always false
      a == [] or b == [] or a == :nothing or b == :nothing ->
        false

      # numbers
      is_number(a) and is_number(b) ->
        a < b

      # strings (RFC: empty string < any non-empty, lexicographic order)
      is_binary(a) and is_binary(b) ->
        cond do
          a == "" and b != "" -> true
          a != "" and b == "" -> false
          true -> a < b
        end

      # everything else cannot be ordered
      true ->
        false
    end
  end

  defp run_singular_query(node, qsegs) do
    # qsegs is list of {:qname, name} or {:qindex, idx}
    # start at node with path []
    walk_query([{[], node}], qsegs)
  end

  defp walk_query(nodes, []), do: nodes

  defp walk_query(nodes, [seg | rest]) do
    next =
      Enum.flat_map(nodes, fn {path, node} ->
        case seg do
          {:qname, name} ->
            case node do
              %{} = m ->
                name_str = to_string(name)
                IO.inspect({name_str, m, Map.has_key?(m, name_str)}, label: "qname_lookup")

                case Map.fetch(m, name_str) do
                  {:ok, v} ->
                    IO.inspect({path ++ [name_str], v}, label: "qname_found")
                    [{path ++ [name_str], v}]

                  :error ->
                    IO.inspect("qname_not_found", label: "qname_result")
                    []
                end

              _ ->
                []
            end

          {:qindex, idx} when is_integer(idx) ->
            case node do
              l when is_list(l) ->
                n = length(l)
                i = if idx < 0, do: n + idx, else: idx
                if i >= 0 and i < n, do: [{path ++ [i], Enum.at(l, i)}], else: []

              _ ->
                []
            end

          {:qwildcard} ->
            case node do
              %{} = m ->
                Enum.map(Map.to_list(m), fn {k, v} -> {path ++ [to_string(k)], v} end)

              l when is_list(l) ->
                Enum.with_index(l) |> Enum.map(fn {v, i} -> {path ++ [i], v} end)

              _ ->
                []
            end

          {:qslice, slice} ->
            case node do
              l when is_list(l) ->
                indices = normalize_slice(length(l), slice)
                Enum.map(indices, fn i -> {path ++ [i], Enum.at(l, i)} end)

              _ ->
                []
            end

          {:qdescendant_name, name} ->
            # Collect all descendants and look for the name
            descendants = collect_descendants_for_query({path, node})

            Enum.flat_map(descendants, fn {desc_path, desc_node} ->
              case desc_node do
                %{} = m ->
                  name_str = to_string(name)

                  case Map.fetch(m, name_str) do
                    {:ok, v} ->
                      [{desc_path ++ [name_str], v}]

                    :error ->
                      []
                  end

                _ ->
                  []
              end
            end)

          {:qdescendant_wildcard} ->
            # Collect all descendants and apply wildcard to each
            descendants = collect_descendants_for_query({path, node})

            Enum.flat_map(descendants, fn {desc_path, desc_node} ->
              case desc_node do
                %{} = m ->
                  Enum.map(Map.to_list(m), fn {k, v} -> {desc_path ++ [to_string(k)], v} end)

                l when is_list(l) ->
                  Enum.with_index(l) |> Enum.map(fn {v, i} -> {desc_path ++ [i], v} end)

                _ ->
                  []
              end
            end)

          {:qdescendant_index, idx} when is_integer(idx) ->
            # Collect all descendants and apply index to lists
            descendants = collect_descendants_for_query({path, node})

            Enum.flat_map(descendants, fn {desc_path, desc_node} ->
              case desc_node do
                l when is_list(l) ->
                  n = length(l)
                  i = if idx < 0, do: n + idx, else: idx
                  if i >= 0 and i < n, do: [{desc_path ++ [i], Enum.at(l, i)}], else: []

                _ ->
                  []
              end
            end)

          {:qdescendant_slice, slice} ->
            # Collect all descendants and apply slice to lists
            descendants = collect_descendants_for_query({path, node})

            Enum.flat_map(descendants, fn {desc_path, desc_node} ->
              case desc_node do
                l when is_list(l) ->
                  indices = normalize_slice(length(l), slice)
                  Enum.map(indices, fn i -> {desc_path ++ [i], Enum.at(l, i)} end)

                _ ->
                  []
              end
            end)
        end
      end)

    walk_query(next, rest)
  end

  defp path_join(parts) do
    "$" <>
      Enum.map_join(tl(parts), "", fn
        part when is_integer(part) ->
          "[#{part}]"

        part when is_binary(part) ->
          "['#{escape_json_string(part)}']"

        part when is_atom(part) ->
          "['#{escape_json_string(Atom.to_string(part))}']"
      end)
  end

  defp collect_descendants_for_query({path, value}) do
    case value do
      %{} = m ->
        base = [{path, value}]

        children =
          Enum.flat_map(Map.to_list(m), fn {k, v} ->
            child_path = path ++ [to_string(k)]
            collect_descendants_for_query({child_path, v})
          end)

        base ++ children

      l when is_list(l) ->
        base = [{path, value}]

        children =
          Enum.with_index(l)
          |> Enum.flat_map(fn {v, idx} ->
            child_path = path ++ [idx]
            collect_descendants_for_query({child_path, v})
          end)

        base ++ children

      _ ->
        [{path, value}]
    end
  end

  defp lookup(map, key, opts) when is_map(map) do
    mode = Keyword.get(opts, :key_mode, :string)

    case {mode, key} do
      {:string, k} ->
        case Map.fetch(map, to_string(k)) do
          {:ok, v} -> {:ok, v, to_string(k)}
          :error -> :error
        end

      {:atom, k} when is_binary(k) ->
        atom_key = String.to_existing_atom(k)

        case Map.fetch(map, atom_key) do
          {:ok, v} -> {:ok, v, atom_key}
          :error -> :error
        end

      {:both, k} ->
        str_k = to_string(k)

        case Map.fetch(map, str_k) do
          {:ok, v} ->
            {:ok, v, str_k}

          :error ->
            atom_k = String.to_existing_atom(str_k)

            case Map.fetch(map, atom_k) do
              {:ok, v} -> {:ok, v, atom_k}
              :error -> :error
            end
        end
    end
  end

  defp get_root_data([{["$"], root_data} | _]), do: root_data
  defp get_root_data(_), do: nil

  defp escape_json_string(s) do
    s
    |> String.replace("\\", "\\\\")
    |> String.replace("\"", "\\\"")
    |> String.replace("\'", "\\\'")
    |> String.replace("\n", "\\n")
    |> String.replace("\r", "\\r")
    |> String.replace("\t", "\\t")
    |> String.replace("\b", "\\b")
    |> String.replace("\f", "\\f")
  end
end
